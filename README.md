# Lab Task 1 â€“ Data Visualization & Cleaning

This repository contains my **first lab task** focused on **data cleaning, exploratory data analysis (EDA), and data visualization** using Python.  
The project demonstrates how to handle raw data, clean it, and extract meaningful insights through various visualization techniques.


---

## ğŸš€ Key Objectives
- Perform **data cleaning** to handle missing values, duplicates, and incorrect data types.
- Conduct **exploratory data analysis (EDA)** to uncover trends, patterns, and relationships.
- Create **visualizations** using Python libraries to better understand the data distribution.

---

## ğŸ› ï¸ Technologies & Libraries
- **Python 3.x**
- **Jupyter Notebook**
- **pandas** â€“ Data manipulation and analysis
- **numpy** â€“ Numerical computations
- **matplotlib** â€“ Data visualization
- **seaborn** â€“ Advanced visualizations

---

## ğŸ“Š Dataset
The dataset used in this task was provided as part of the lab exercise.  
Add the following details if available:
- **Dataset Name**: *(e.g., sales.csv, students.csv, etc.)*
- **Number of Rows & Columns**: *(e.g., 1000 rows Ã— 12 columns)*
- **Description**: Brief info about the type of data (e.g., sales records, student marks, customer information, etc.)

---

## âš¡ Steps Performed
1. **Importing Data**  
   - Loaded the dataset using `pandas`.
2. **Data Cleaning**  
   - Checked for missing values and duplicates.
   - Fixed incorrect data types where required.
3. **Exploratory Data Analysis (EDA)**  
   - Generated summary statistics.
   - Explored relationships between key features.
4. **Visualization**  
   - Created graphs (bar charts, histograms, scatter plots, etc.) using **Matplotlib** and **Seaborn**.

---

## ğŸ’¡ Results & Insights
- Cleaned dataset ready for further analysis or machine learning tasks.
- Visualizations revealed key trends, outliers, and data distribution patterns.
- Improved understanding of the dataset for decision-making.



